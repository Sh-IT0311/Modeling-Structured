### 2. 데이터 탐색 및 EDA(Exploratory Data Analysis)
* 현재 과정은 데이터 이해 및 인사이트를 도출해내는 단계
* **데이터로 직접 보기 전까지는 함부로 판단하지 말자**
* **Data Driven Decision : EAVO(EDA → Action → Verify → Output)**
* 결국 데이터의 품질이 뒷받침이 되어야 높은 성능을 도출해낼 수 있는 만큼 충분한 시간 투자하기
* EDA는 두가지 관점에서 진행할 수 있음
    * Feature Engineering 관점에서 아이디어를 획득
    * Business 관점에서 영향력 있는 Feature 발굴(→ 결정권자에게 설득하는 관점)
* 훈련 세트가 너무 클 경우, 샘플링해서 진행 할 수도 있음
* 최대한 절대적인 스케일(ex> 개수)보단 상대적인 스케일(ex> 비율)로 접근하자
    * 절대적인 스케일은 수집된 데이터의 개수에 따라 크게 달라짐
* 주의할 점
    * 일부 구간만 확인하고 경향성을 파악하는 실수 하지 않기
        * 실제 모델의 성능을 향상시킬 수 있는 feature를 놓친 경험이 있음
    * 분석결과가 애매하면 무조건 모델 측면에서 성능 확인하기
    * No Free Lunch(공짜 점심 없음)
        * 경험해보기 전까지 해당 데이터에 더 잘 맞을 것이라고 보장할 수 있는 모델은 존재하지 않음
            * ≈ 모델마다 요구되는 Feature Engineering이 다를 수 있음
            * 일반화를 저해하는 요소는 모델의 원리에 따라 다르게 정해짐
        * 데이터의 복잡도(= 복잡한 관계), 데이터의 크기, 데이터의 성격을 고려해 적합한 모델들을 선택해서 비교하는 과정이 필요함
    * Mean/Median 뿐만 아니라 다양한 통계치를 활용하기
        * 예를 들어 결측치를 채우고자 Group Mean를 활용할 Feature를 선정할 때 Group Variance가 적은 Feature를 선정하는 것이 합리적임
* 주요과정
    * 데이터 개수 및 구성된 특성들 확인
        * feature description 활용
    * test set이 없을 경우 데이터 셋 분리(Train, Test)
        * test set이 실전에서 기대하는 데이터를 가능한 잘 대표해야 적절한 일반화 오차 추정치를 얻을 수 있음
            * 전체 데이터 셋에서 샘플링 방식이 중요함
                * 데이터 셋의 수가 충분히 크다면 (특히 특성 수에 비해) 무작위 방식은 일반적으로 괜찮음
                * 그렇지 않거나 Target Imbalance와 같은 특수한 상황에서는 대표성을 띠지 않는 샘플링 편향을 일으킬 수 있음
            * 데이터 개수가 부족한 경우 최대한 많은 train set을 확보하기 위해 valid/test set 구성없이 cross validation으로 일반화 정도를 가늠해 볼 수 있는데, 이런 경우 각 fold를 잘 샘플링 해야됨
        * split 비율은 데이터 셋 규모에 따라 다름
            * ex> 데이터셋 크면 적은 비율
        * (caution) **테스트 세트는 완전히 Unseen**
            * 데이터 스누핑 편향
                * 테스트 세트에 대한 성능을 직접적으로 최적화하면 매우 낙관적인 추정이 되어 시스템을 론칭했을 때 기대한 성능이 나오지 않는 문제
            * 난수 발생기의 초깃값을 지정하여 테스트 세트 고정
                * 데이터 세트가 업데이트가 되면 문제가 될 수 있음
            * **train에 적용했던 전처리는 test에 똑같이 적용**
                * train set : fit & transform
                * test set : transform
    * 데이터 개수 확인
    * 중복행 확인 및 제거
    * 결측값 확인
    * 특성 통계치 확인
        * 비상식적인 값 확인
            * ex> 나이(age)를 나타내는 변수의 min 값이 음수가 나옴 <-> 현실적으로 나이는 음수가 나올 수 없다.
    * 오타 확인
        * 특히 string type 경우
    * **시각화**
        * 상황에 맞는, 경향성을 이해하기 쉬운 적절한 시각화를 사용해야함
        1. 종속변수(Target variable)의 분포
            * Data Imbalance(Classification)
                * Binary Classification에서 Minor Class를 1로 맵핑하는게 좋음
                    * Precision, Recall이 양성샘플(1)에 초점을 두고 있는 Measure이기 때문에 Minor Class를 예측하는 정도를 알 수 있음
                * Data Imbalance를 판단하는 정성적인 방법
                    1. Target Variable Ratio를 통해 의심
                    2. Sampling과 같은 Feature Engineering 없이 학습 후 Precision, Recall 확인
                        * Precision, Recall의 성능이 좋지 못하면 Data Imbalance로 판단
                * 다수 클래스에 편향된 Decision Boundary를 형성함
                    * UnderSampling / OverSampling
                    * Cost Sensitve Learning
                * 불균형할 때 주의할 점
                    * 시각화
                    * 상관계수
                    * 모델학습
                    * 교차검증(Cross Validation)
                        * Fold 분할 이후, Train Folds에 대해서 Sampling을 진행함
            * Skewed Target Variable(Regression)
                * Target Variable의 분포에 따라 마치 Cost Sensitive Learning이 이루어짐
                    * Log Transformation
                        * 음수 일 때 주의
                        * Mean Encoding을 고려할 경우, Mean Encoding 이전 또는 이후 Transform 시점 결정 필요함
        2. 독립변수 (명목형/수치형) 의 분포
            * Ordinal Categorical Feature와 Numerical Feature 간에 딜레마가 있음
                * Ex> Age(나이), Tenure(가입기간)
            * Numerical Feature
                * Skewness 및 이상치 확인
                * 특성 스케일 확인
            * Categorical Feature
                * 카디널리티 확인 및 축소 방법 연구
                * Encoding 방법 연구
        3. 종속변수-독립변수 / 독립변수-독립변수 간의 분포
            * Categorical Feature vs Categorical Feature
                * Counter Plot / Bar Plot
                    * Total Ratio와 Group별 Ratio를 비교함
            * Categorical Feature vs Numerical Feature
                * KDE Plot
                    * Normalization이 되어 있는 각 Distribution에 대해서 통계치를 비교함
                        * 통계치 예시 : Mean, Standard Deviation
            * Numerical Feature vs Numerical Feature
                * Scatter
                    * Linear, Quadratic 등 경향성을 포착함
        4. Advance
            * 3개 이상의 Feature를 고려해보기
    * 특이한점 확인
        * 특성의 단위 확인
        * (핸즈 온 머신러닝에서 언급된 특정 예시)한정된 최댓값, 최솟값
            * 상황에 따라 한곗값 밖의 구역에 대한 정확한 레이블을 구하거나 또는 데이터에서 제거해야함
    * 상관관계 확인
        * 기본적으로 feature 간에 선형성만 확인 할 수 있음
        * categorical feature vs numerical feature
            * categorical feature가 ordinal category 또는 binary category 일 경우는 상관관계를 활용 할 수 있을 것 같음
            * categorical feature가 nomial category인 경우는 상관관계 해석이 부적합 할 것 같음
        * numerical feature vs numerical feature의 경우는 상관관계 해석이 요구됨
    * 고려하는 모델들의 원리에 부합하는지 확인
        * 예를 들어 복잡한 관계를 가지고 있는 데이터에 대해서 Linear Regression이 적합할까?